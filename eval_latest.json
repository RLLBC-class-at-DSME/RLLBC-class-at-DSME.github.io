{
    "timestamp": "2024-05-28_14-31-26",
    "groups": {
        "1": {
            "error": true,
            "error_msg": "Traceback (most recent call last):\n  File \"C:\\Users\\limar\\Desktop\\Studium\\Hiwi\\Car_Racing_Challenge\\students_repo\\group_1\\evaluation_script.py\", line 66, in <module>\n    from agent_interface import convert_obs, convert_action\n  File \"C:\\Users\\limar\\Desktop\\Studium\\Hiwi\\Car_Racing_Challenge\\students_repo\\group_1\\agent_interface.py\", line 114\n    class DDPG_Agent(nn.Module): \nIndentationError: expected an indented block after class definition on line 111\n]",
            "mean": -1,
            "std": -1,
            "commit-SHA": "b5871f6e7678f57f6937b46dd521fd2248cbf613"
        },
        "2": {
            "error": true,
            "error_msg": "Traceback (most recent call last):\n  File \"C:\\Users\\limar\\Desktop\\Studium\\Hiwi\\Car_Racing_Challenge\\students_repo\\group_2\\evaluation_script.py\", line 89, in <module>\n    mean_reward, std_reward = evaluate_agent(model_file, convert_obs, convert_action, seed=args.seed, tracks=tracks)\n  File \"C:\\Users\\limar\\Desktop\\Studium\\Hiwi\\Car_Racing_Challenge\\students_repo\\group_2\\evaluation_script.py\", line 31, in evaluate_agent\n    model = load_model(model_file)\n  File \"C:\\Users\\limar\\Desktop\\Studium\\Hiwi\\Car_Racing_Challenge\\students_repo\\group_2\\evaluation_script.py\", line 24, in load_model\n    model = pickle.load(model_file)\n  File \"C:\\Users\\limar\\miniconda3\\envs\\test-eval-env\\lib\\site-packages\\torch\\storage.py\", line 337, in _load_from_bytes\n    return torch.load(io.BytesIO(b))\n  File \"C:\\Users\\limar\\miniconda3\\envs\\test-eval-env\\lib\\site-packages\\torch\\serialization.py\", line 1028, in load\n    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n  File \"C:\\Users\\limar\\miniconda3\\envs\\test-eval-env\\lib\\site-packages\\torch\\serialization.py\", line 1256, in _legacy_load\n    result = unpickler.load()\n  File \"C:\\Users\\limar\\miniconda3\\envs\\test-eval-env\\lib\\site-packages\\torch\\serialization.py\", line 1193, in persistent_load\n    wrap_storage=restore_location(obj, location),\n  File \"C:\\Users\\limar\\miniconda3\\envs\\test-eval-env\\lib\\site-packages\\torch\\serialization.py\", line 381, in default_restore_location\n    result = fn(storage, location)\n  File \"C:\\Users\\limar\\miniconda3\\envs\\test-eval-env\\lib\\site-packages\\torch\\serialization.py\", line 274, in _cuda_deserialize\n    device = validate_cuda_device(location)\n  File \"C:\\Users\\limar\\miniconda3\\envs\\test-eval-env\\lib\\site-packages\\torch\\serialization.py\", line 258, in validate_cuda_device\n    raise RuntimeError('Attempting to deserialize object on a CUDA '\nRuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.\n]",
            "mean": -1,
            "std": -1,
            "commit-SHA": "7ccfc5c1ece2ab463ef10295f6f03622ef8e52a0"
        }
    }
}